{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9b1d4ce",
   "metadata": {},
   "source": [
    "# Elbow data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "036d58a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze_elbow_effusion.py\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nibabel as nib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dfae46",
   "metadata": {},
   "source": [
    "## Elbow Ultrasound Multireader Trial\n",
    "\n",
    "- This notebook processes and analyzes elbow ultrasound data from a multireader trial.\n",
    "- The dataset contains fracture and effusion annotations from two radiologists: JJ and JK.\n",
    "- For consistency, we limit our analysis to labels from **JJ** only.\n",
    "\n",
    "\n",
    "Reference spreadsheet: [Google Sheets](https://docs.google.com/spreadsheets/d/14an9mxel6_QW3PvJL-gBSHTyw-nTkD2m/edit?usp=sharing&ouid=101373979316677349346&rtpof=true&sd=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a287c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Randomized ID</th>\n",
       "      <th>Study ID</th>\n",
       "      <th>JK US Fracture</th>\n",
       "      <th>JJ US Fracture</th>\n",
       "      <th>US Fracture Agree?</th>\n",
       "      <th>JK XR Fracture</th>\n",
       "      <th>JJ XR Fracture</th>\n",
       "      <th>XR Fracture Agree?</th>\n",
       "      <th>JK US Effusion?</th>\n",
       "      <th>JJ US Effusion?</th>\n",
       "      <th>US Effusion Agree?</th>\n",
       "      <th>JK XR Effusion?</th>\n",
       "      <th>JJ XR Effusion?</th>\n",
       "      <th>XR Effusion Agree?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EL001</td>\n",
       "      <td>88105 elbow 2D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EL002</td>\n",
       "      <td>88098 elbow 2D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EL003</td>\n",
       "      <td>W00004 elbow 3D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EL004</td>\n",
       "      <td>88106 elbow 2D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EL005</td>\n",
       "      <td>88026 elbow 2D</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>EL128</td>\n",
       "      <td>88099 elbow 3D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>EL129</td>\n",
       "      <td>88070 elbow 3D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>EL130</td>\n",
       "      <td>88162 elbow 3D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>EL131</td>\n",
       "      <td>88055 elbow 3D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>EL132</td>\n",
       "      <td>88156 elbow 2D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Randomized ID         Study ID  JK US Fracture  JJ US Fracture  \\\n",
       "0           EL001   88105 elbow 2D               0               0   \n",
       "1           EL002   88098 elbow 2D               1               1   \n",
       "2           EL003  W00004 elbow 3D               0               0   \n",
       "3           EL004   88106 elbow 2D               0               0   \n",
       "4           EL005   88026 elbow 2D               0               1   \n",
       "..            ...              ...             ...             ...   \n",
       "127         EL128   88099 elbow 3D               0               0   \n",
       "128         EL129   88070 elbow 3D               0               0   \n",
       "129         EL130   88162 elbow 3D               0               0   \n",
       "130         EL131   88055 elbow 3D               0               0   \n",
       "131         EL132   88156 elbow 2D               0               0   \n",
       "\n",
       "     US Fracture Agree?  JK XR Fracture  JJ XR Fracture  XR Fracture Agree?  \\\n",
       "0                     0             0.0             0.0                   0   \n",
       "1                     2             1.0             1.0                   2   \n",
       "2                     0             NaN             NaN                   0   \n",
       "3                     0             0.0             0.0                   0   \n",
       "4                     1             0.0             0.0                   0   \n",
       "..                  ...             ...             ...                 ...   \n",
       "127                   0             1.0             0.0                   1   \n",
       "128                   0             NaN             NaN                   0   \n",
       "129                   0             0.0             0.0                   0   \n",
       "130                   0             0.0             0.0                   0   \n",
       "131                   0             0.0             1.0                   1   \n",
       "\n",
       "     JK US Effusion?  JJ US Effusion?  US Effusion Agree?  JK XR Effusion?  \\\n",
       "0                  0                0                   0              0.0   \n",
       "1                  1                1                   2              1.0   \n",
       "2                  0                0                   0              NaN   \n",
       "3                  1                1                   2              0.0   \n",
       "4                  1                1                   2              0.0   \n",
       "..               ...              ...                 ...              ...   \n",
       "127                1                1                   2              1.0   \n",
       "128                0                0                   0              NaN   \n",
       "129                1                0                   1              0.0   \n",
       "130                0                0                   0              0.0   \n",
       "131                1                0                   1              0.0   \n",
       "\n",
       "     JJ XR Effusion?  XR Effusion Agree?  \n",
       "0                0.0                   0  \n",
       "1                1.0                   2  \n",
       "2                NaN                   0  \n",
       "3                0.0                   0  \n",
       "4                1.0                   1  \n",
       "..               ...                 ...  \n",
       "127              1.0                   2  \n",
       "128              NaN                   0  \n",
       "129              0.0                   0  \n",
       "130              0.0                   0  \n",
       "131              0.0                   0  \n",
       "\n",
       "[132 rows x 14 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and select JJ’s columns\n",
    "csv_path = Path(r\"M:\\ElbowProject\\Elbow XR US.csv\")   \n",
    "df = pd.read_csv(csv_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe4c5b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Randomized ID', 'Study ID', 'JK US Fracture', 'JJ US Fracture',\n",
       "       'US Fracture Agree?', 'JK XR Fracture', 'JJ XR Fracture',\n",
       "       'XR Fracture Agree?', 'JK US Effusion?', 'JJ US Effusion?',\n",
       "       'US Effusion Agree?', 'JK XR Effusion?', 'JJ XR Effusion?',\n",
       "       'XR Effusion Agree?'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rows = len(df)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fbb08bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped study IDs due to missing diagnostic labels:\n",
      "['W00004 elbow 3D', '88137 elbow 3D', '88128 elbow 2D', '88126 elbow 2D', '88137 elbow 2D', '88159 elbow 2D', 'W00001 elbow 3D', '88019 elbow 3D', '88102 elbow 3D', 'W00008 elbow 2D', '88019 elbow 2D', '88061 elbow 3D', 'W00008 elbow 3D', '88061 elbow 2D', '88159 elbow 3D', '88128 elbow 3D', '88057 elbow 3D', '88102 elbow 2D', '88028 elbow 2D', '88070 elbow 2D', '88057 elbow 2D', 'W00001 elbow 2D', '88070 elbow 3D']\n",
      "Dataset ready: 109 examinations\n"
     ]
    }
   ],
   "source": [
    "# Load and Clean JJ-Labeled Data\n",
    "# We rename relevant JJ columns and drop rows with missing values in the diagnostic labels.\n",
    "\n",
    "\n",
    "keep = {\n",
    "    \"Study ID\"         : \"study_id\",\n",
    "    \"JJ US Effusion?\"  : \"us_effusion\",\n",
    "    \"JJ XR Effusion?\"  : \"xr_effusion\",\n",
    "    \"JJ US Fracture\"   : \"us_fracture\",\n",
    "    \"JJ XR Fracture\"   : \"xr_fracture\",\n",
    "}\n",
    "\n",
    "df = df[keep.keys()].rename(columns=keep)\n",
    "\n",
    "# force 0/1 integers, drop rows with NaNs in diagnostic columns\n",
    "diag = [\"us_effusion\", \"xr_effusion\", \"us_fracture\", \"xr_fracture\"]\n",
    "df[diag] = df[diag].apply(pd.to_numeric, errors=\"coerce\").astype(\"Int64\")\n",
    "# Identify rows that will be dropped (have NaN in any of the diag columns)\n",
    "dropped_rows = df[df[diag].isnull().any(axis=1)]\n",
    "# Summary of Dropped Rows\n",
    "# Print their study IDs\n",
    "print(\"Dropped study IDs due to missing diagnostic labels:\")\n",
    "dropped_studies = dropped_rows['study_id'].tolist()\n",
    "print(dropped_studies)\n",
    "\n",
    "df = df.dropna(subset=diag).astype({c: int for c in diag})\n",
    "\n",
    "print(f\"Dataset ready: {len(df)} examinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4cd3f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 23 rows with missing information\n",
      "Cleaned dataset has 109 rows\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset has {len(dropped_studies)} rows with missing information\")\n",
    "print(f\"Cleaned dataset has {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681dd785",
   "metadata": {},
   "source": [
    "- A total of 23 studies were excluded due to missing fracture or effusion labels from radiologist JJ. This leaves us with 109 fully labeled studies for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0704ac4",
   "metadata": {},
   "source": [
    "### Elbow Ultrasound Study Types\n",
    "\n",
    "This spreadsheet includes both **2D** and **3D** ultrasound studies:\n",
    "\n",
    "- **2D studies** were acquired using a **Philips Lumify** system with an **L5-12 (5–12 MHz) transducer**.\n",
    "- **3D studies** were acquired using a **Philips IU22** system with a **VL13-5 (13 MHz) transducer**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a08aa70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2D IDs: ['88128', '88126', '88137', '88159', 'W00008', '88019', '88061', '88102', '88028', '88070', '88057', 'W00001']\n",
      "Dropped 3D IDs: ['W00004', '88137', 'W00001', '88019', '88102', '88061', 'W00008', '88159', '88128', '88057', '88070']\n"
     ]
    }
   ],
   "source": [
    "# Categorize dropped studies based on whether they belong to 2D (Lumify) or 3D (IU22) acquisition.\n",
    "# Extract dropped ID and categorize\n",
    "IDs_2D = []\n",
    "IDs_3D = []\n",
    "\n",
    "for s in dropped_studies:\n",
    "    match = re.search(r'(W\\d{5}|\\d{5})', s)\n",
    "    if match:\n",
    "        study_id = match.group()\n",
    "        if '2D' in s:\n",
    "            IDs_2D.append(study_id)\n",
    "        elif '3D' in s:\n",
    "            IDs_3D.append(study_id)\n",
    "\n",
    "# Results\n",
    "print(\"Dropped 2D IDs:\", IDs_2D)\n",
    "print(\"Dropped 3D IDs:\", IDs_3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c0b805",
   "metadata": {},
   "source": [
    "- Among the dropped cases, 12 were 2D studies (from Lumify) and 11 were 3D studies (from IU22). These are excluded from further analysis due to incomplete annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd9bab1",
   "metadata": {},
   "source": [
    "### Extracting and Summarizing Study IDs by Modality\n",
    "\n",
    "In this step, we:\n",
    "\n",
    "1. **Extracted numeric study IDs** from the `study_id` field.\n",
    "2. **Grouped studies** based on imaging modality:\n",
    "   - **2D** studies (Philips Lumify L5-12 MHz)\n",
    "   - **3D** studies (Philips IU22 VL13-5 MHz)\n",
    "3. **Counted total and unique studies** to ensure proper tracking and avoid duplicate entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b464001f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_IDs = ['88105', '88098', '88106', '88026', '88042', '88098', '88148', '88023', '88068', '88022', '88025', '88072', '88105', '88133', '88156', '88077', '88069', '88141', '88093', '88017', '88118', '88131', '88132', '88158', '88082', '88074', '88145', '88034', '88095', '88133', '88015', '88077', '88082', '88145', '88135', '88112', '88131', '88118', '88069', '88170', '88010', '88090', '88138', '88114', '88091', '88150', '88015', '88072', '88075', '88036', '88034', '88112', '88111', '88037', '88091', '88010', '88152', '88150', '88058', '88037', '88078', '88096', '88170', '88094', '88119', '88017', '88172', '88154', '88025', '88148', '88135', '88094', '88114', '88154', '88084', '88078', '88099', '88033', '88111', '88132', '88084', '88095', '88119', '88022', '88141', '88158', '88058', '88172', '88075', '88026', '88090', '88152', '88074', '88055', '88096', '88068', '88122', '88097', '88033', '88023', '88162', '88049', '88138', '88122', '88106', '88099', '88162', '88055', '88156']\n",
      "file_IDs:  109\n",
      "IDs_2D = ['88105', '88098', '88106', '88026', '88148', '88022', '88072', '88131', '88082', '88145', '88034', '88095', '88133', '88077', '88112', '88118', '88069', '88170', '88090', '88150', '88015', '88036', '88111', '88091', '88010', '88037', '88096', '88094', '88017', '88025', '88135', '88114', '88154', '88084', '88078', '88099', '88033', '88132', '88119', '88141', '88158', '88058', '88172', '88075', '88152', '88074', '88055', '88068', '88122', '88097', '88023', '88162', '88049', '88138', '88156']\n",
      "IDs_2D:  55\n",
      "IDs_3D = ['88042', '88098', '88023', '88068', '88025', '88105', '88133', '88156', '88077', '88069', '88141', '88093', '88017', '88118', '88132', '88158', '88074', '88015', '88082', '88145', '88135', '88131', '88010', '88138', '88114', '88091', '88072', '88075', '88034', '88112', '88037', '88152', '88150', '88058', '88078', '88170', '88119', '88172', '88154', '88148', '88094', '88111', '88084', '88095', '88022', '88026', '88090', '88096', '88033', '88122', '88106', '88099', '88162', '88055']\n",
      "IDs_3D:  54\n",
      "unique studies: ['88010' '88015' '88017' '88022' '88023' '88025' '88026' '88033' '88034'\n",
      " '88036' '88037' '88042' '88049' '88055' '88058' '88068' '88069' '88072'\n",
      " '88074' '88075' '88077' '88078' '88082' '88084' '88090' '88091' '88093'\n",
      " '88094' '88095' '88096' '88097' '88098' '88099' '88105' '88106' '88111'\n",
      " '88112' '88114' '88118' '88119' '88122' '88131' '88132' '88133' '88135'\n",
      " '88138' '88141' '88145' '88148' '88150' '88152' '88154' '88156' '88158'\n",
      " '88162' '88170' '88172']\n",
      "Number of unique studies: 57\n",
      "Present in 2D but not in 3D: ['88036', '88049', '88097']\n",
      "Count: 3\n",
      "Present in 3D but not in 2D: ['88042', '88093']\n",
      "Count: 2\n"
     ]
    }
   ],
   "source": [
    "# === Extract alphanumeric file IDs from 'study_id' ===\n",
    "df['file_id'] = df['study_id'].str.extract(r'(W\\d{5}|\\d{5})', expand=False).str.upper()\n",
    "\n",
    "# === Categorize as 2D or 3D ===\n",
    "IDs_2D = df[df['study_id'].str.contains('2D', case=False)]['file_id'].tolist()\n",
    "IDs_3D = df[df['study_id'].str.contains('3D', case=False)]['file_id'].tolist()\n",
    "file_IDs = df['file_id'].tolist()\n",
    "\n",
    "# === Print summary ===\n",
    "print(\"file_IDs =\", file_IDs)\n",
    "print(\"file_IDs: \", len(file_IDs))\n",
    "print(\"IDs_2D =\", IDs_2D)\n",
    "print(\"IDs_2D: \", len(IDs_2D))\n",
    "print(\"IDs_3D =\", IDs_3D)\n",
    "print(\"IDs_3D: \", len(IDs_3D))\n",
    "\n",
    "# Unique IDs\n",
    "unique_ids = np.unique(file_IDs)\n",
    "print(\"unique studies:\", unique_ids)\n",
    "print(\"Number of unique studies:\", len(unique_ids))\n",
    "\n",
    "# === Differences ===\n",
    "\n",
    "# === Compute differences ===\n",
    "\n",
    "set_2D = set(IDs_2D)\n",
    "set_3D = set(IDs_3D)\n",
    "\n",
    "only_in_2D = sorted(set_2D - set_3D)\n",
    "only_in_3D = sorted(set_3D - set_2D)\n",
    "\n",
    "print(\"Present in 2D but not in 3D:\", only_in_2D)\n",
    "print(\"Count:\", len(only_in_2D))\n",
    "\n",
    "print(\"Present in 3D but not in 2D:\", only_in_3D)\n",
    "print(\"Count:\", len(only_in_3D))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aeac3b",
   "metadata": {},
   "source": [
    "- We have 109 total examinations, split across 55 2D and 54 3D studies. After extracting unique IDs, we find 57 distinct patients, suggesting that many had both 2D and 3D imaging.\n",
    "- 3 file IDs appear only in 2D studies and 2 appear only in 3D. The rest (52) had both imaging modalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a4648f",
   "metadata": {},
   "source": [
    "### Comparing Spreadsheet Study IDs with Local Data\n",
    "\n",
    "In this step, we compare the list of study IDs from the **JJ-labeled spreadsheet** with the **locally available ultrasound data** on disk.\n",
    "\n",
    "- **Local 3D data**: `B:\\US_Data_backup\\Elbow Data\\3D iU22 Elbow Data\\_3D iU22 Elbow Data`\n",
    "- **Local 2D data**: `B:\\US_Data_backup\\Elbow Data\\2D Lumify Elbow Data\\_2D Lumify Elbow Data`\n",
    "\n",
    "We:\n",
    "1. Extracted numeric study IDs from folder/file names.\n",
    "2. Identified:\n",
    "   -  IDs found in both spreadsheet and local storage\n",
    "   -  IDs present in the spreadsheet but missing locally\n",
    "   -  IDs present locally but not listed in the spreadsheet\n",
    "\n",
    "This comparison ensures data consistency before further analysis and flags any missing or extra cases that need investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "880962af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 2D Comparison ===\n",
      " Common: ['88010', '88015', '88017', '88022', '88023', '88025', '88026', '88033', '88034', '88036', '88037', '88049', '88055', '88058', '88068', '88069', '88072', '88074', '88075', '88077', '88078', '88082', '88084', '88090', '88091', '88094', '88095', '88096', '88097', '88098', '88099', '88105', '88106', '88111', '88112', '88114', '88118', '88119', '88122', '88131', '88132', '88133', '88135', '88138', '88141', '88145', '88148', '88150', '88152', '88154', '88156', '88158', '88162', '88170', '88172']\n",
      " Missing in local 2D: []\n",
      " Extra in local 2D: ['88019', '88028', '88057', '88061', '88070', '88102', '88126', '88128', '88137', '88159', 'W00001', 'W00008']\n",
      "\n",
      "=== 3D Comparison ===\n",
      " Common: ['88010', '88015', '88017', '88022', '88023', '88025', '88026', '88033', '88034', '88037', '88042', '88055', '88058', '88068', '88069', '88072', '88074', '88075', '88077', '88078', '88082', '88084', '88090', '88091', '88093', '88094', '88095', '88096', '88098', '88099', '88105', '88106', '88111', '88112', '88114', '88118', '88119', '88122', '88131', '88132', '88133', '88135', '88138', '88141', '88145', '88148', '88150', '88152', '88154', '88156', '88158', '88162', '88170', '88172']\n",
      " Missing in local 3D: []\n",
      " Extra in local 3D: ['88019', '88057', '88061', '88070', '88102', '88128', '88137', '88159', 'W00001', 'W00004', 'W00008']\n"
     ]
    }
   ],
   "source": [
    "# === Define local paths ===\n",
    "folder_2D = Path(r'B:\\US_Data_backup\\Elbow Data\\2D Lumify Elbow Data\\_2D Lumify Elbow Data')\n",
    "folder_3D = Path(r'B:\\US_Data_backup\\Elbow Data\\3D iU22 Elbow Data\\_3D iU22 Elbow Data')\n",
    "\n",
    "\n",
    "def extract_study_ids(folder):\n",
    "    ids = set()\n",
    "    for f in folder.iterdir():\n",
    "        # Match IDs like 88105 or W00004\n",
    "        match = re.search(r'\\b(?:W\\d{5}|\\d{5})\\b', f.name, re.IGNORECASE)\n",
    "        if match:\n",
    "            ids.add(match.group().upper())  # Ensure consistent casing (W00004 vs w00004)\n",
    "    return sorted(ids)\n",
    "\n",
    "# Extract from local folders\n",
    "local_2D_ids = extract_study_ids(folder_2D)\n",
    "local_3D_ids = extract_study_ids(folder_3D)\n",
    "\n",
    "# Convert spreadsheet IDs to same format (e.g., strings like '88105' or 'W00004')\n",
    "spreadsheet_2D_ids = [str(i).upper().zfill(5) if isinstance(i, int) else str(i).upper() for i in IDs_2D]\n",
    "spreadsheet_3D_ids = [str(i).upper().zfill(5) if isinstance(i, int) else str(i).upper() for i in IDs_3D]\n",
    "\n",
    "# Convert to sets\n",
    "spreadsheet_2D_ids = set(spreadsheet_2D_ids)\n",
    "spreadsheet_3D_ids = set(spreadsheet_3D_ids)\n",
    "local_2D_ids = set(local_2D_ids)\n",
    "local_3D_ids = set(local_3D_ids)\n",
    "\n",
    "# Compare\n",
    "missing_2D = spreadsheet_2D_ids - local_2D_ids\n",
    "extra_2D = local_2D_ids - spreadsheet_2D_ids\n",
    "common_2D = spreadsheet_2D_ids & local_2D_ids\n",
    "\n",
    "missing_3D = spreadsheet_3D_ids - local_3D_ids\n",
    "extra_3D = local_3D_ids - spreadsheet_3D_ids\n",
    "common_3D = spreadsheet_3D_ids & local_3D_ids\n",
    "\n",
    "# Print summary\n",
    "print(\"=== 2D Comparison ===\")\n",
    "print(\" Common:\", sorted(common_2D))\n",
    "print(\" Missing in local 2D:\", sorted(missing_2D))\n",
    "print(\" Extra in local 2D:\", sorted(extra_2D))\n",
    "\n",
    "print(\"\\n=== 3D Comparison ===\")\n",
    "print(\" Common:\", sorted(common_3D))\n",
    "print(\" Missing in local 3D:\", sorted(missing_3D))\n",
    "print(\" Extra in local 3D:\", sorted(extra_3D))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628ebc71",
   "metadata": {},
   "source": [
    "- All spreadsheet-listed 2D and 3D study IDs are present locally. the extras here correspond to the dropped cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33f7ab20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52 studies with both 2D and 3D\n",
      "XR Fracture Counts for Common 2D/3D Studies:\n",
      "→ 2D view: 13 fractures (39 normals)\n",
      "→ 3D view: 13 fractures (39 normals)\n"
     ]
    }
   ],
   "source": [
    "df['file_id'] = df['study_id'].str.extract(r'(W\\d{5}|\\d{5})', expand=False).str.upper()\n",
    "\n",
    "# Step 2: Separate 2D and 3D entries\n",
    "df_2D = df[df['study_id'].str.contains('2D', case=False)].copy()\n",
    "df_3D = df[df['study_id'].str.contains('3D', case=False)].copy()\n",
    "\n",
    "# Step 3: Find common subjects\n",
    "common_ids = set(df_2D['file_id']) & set(df_3D['file_id'])\n",
    "\n",
    "print(f\"Found {len(common_ids)} studies with both 2D and 3D\")\n",
    "\n",
    "# Filter 2D and 3D rows to only common file_ids\n",
    "df_2D_common = df_2D[df_2D['file_id'].isin(common_ids)]\n",
    "df_3D_common = df_3D[df_3D['file_id'].isin(common_ids)]\n",
    "\n",
    "# Count xr_fracture = 1 in each\n",
    "fx_2D_common = df_2D_common[df_2D_common['xr_fracture'] == 1].shape[0]\n",
    "fx_3D_common = df_3D_common[df_3D_common['xr_fracture'] == 1].shape[0]\n",
    "\n",
    "normal_2D_common = df_2D_common[df_2D_common['xr_fracture'] == 0].shape[0]\n",
    "normal_3D_common = df_3D_common[df_3D_common['xr_fracture'] == 0].shape[0]  \n",
    "\n",
    "print(\"XR Fracture Counts for Common 2D/3D Studies:\")\n",
    "print(f\"→ 2D view: {fx_2D_common} fractures\", \n",
    "      f\"({normal_2D_common} normals)\")\n",
    "print(f\"→ 3D view: {fx_3D_common} fractures\",   \n",
    "      f\"({normal_3D_common} normals)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aec5f0d",
   "metadata": {},
   "source": [
    "\n",
    "To check label consistency for subjects that have both 2D and 3D studies, you can:\n",
    "\n",
    "1. Identify the intersection of 2D and 3D IDs.\n",
    "\n",
    "2. For each overlapping study, compare the values in the label columns (e.g., us_effusion, xr_effusion, etc.).\n",
    "\n",
    "3. Report any mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84364151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52 studies with both 2D and 3D\n",
      "Inconsistent labeling found for the following studies:\n",
      "Study 88015:\n",
      "  - us_fracture: 2D = 0, 3D = 1\n",
      "Study 88022:\n",
      "  - us_effusion: 2D = 1, 3D = 0\n",
      "Study 88023:\n",
      "  - us_effusion: 2D = 1, 3D = 0\n",
      "  - us_fracture: 2D = 1, 3D = 0\n",
      "Study 88025:\n",
      "  - us_fracture: 2D = 1, 3D = 0\n",
      "Study 88026:\n",
      "  - us_fracture: 2D = 1, 3D = 0\n",
      "Study 88034:\n",
      "  - us_effusion: 2D = 1, 3D = 0\n",
      "  - us_fracture: 2D = 1, 3D = 0\n",
      "Study 88037:\n",
      "  - us_fracture: 2D = 1, 3D = 0\n",
      "Study 88068:\n",
      "  - us_fracture: 2D = 1, 3D = 0\n",
      "Study 88072:\n",
      "  - us_fracture: 2D = 1, 3D = 0\n",
      "Study 88074:\n",
      "  - us_effusion: 2D = 1, 3D = 0\n",
      "  - us_fracture: 2D = 1, 3D = 0\n",
      "Study 88075:\n",
      "  - us_effusion: 2D = 1, 3D = 0\n",
      "Study 88099:\n",
      "  - us_fracture: 2D = 1, 3D = 0\n",
      "Study 88106:\n",
      "  - us_fracture: 2D = 0, 3D = 1\n",
      "Study 88132:\n",
      "  - us_fracture: 2D = 1, 3D = 0\n",
      "Study 88133:\n",
      "  - us_fracture: 2D = 0, 3D = 1\n",
      "Study 88138:\n",
      "  - us_effusion: 2D = 1, 3D = 0\n",
      "  - us_fracture: 2D = 1, 3D = 0\n",
      "Study 88156:\n",
      "  - us_effusion: 2D = 0, 3D = 1\n",
      "  - us_fracture: 2D = 0, 3D = 1\n",
      "Study 88158:\n",
      "  - us_effusion: 2D = 1, 3D = 0\n",
      "Study 88162:\n",
      "  - us_effusion: 2D = 1, 3D = 0\n",
      "  - us_fracture: 2D = 1, 3D = 0\n",
      "Number of inconsistent cases: 19\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Ensure file_id is alphanumeric\n",
    "df['file_id'] = df['study_id'].str.extract(r'(W\\d{5}|\\d{5})', expand=False).str.upper()\n",
    "\n",
    "# Step 2: Separate 2D and 3D entries\n",
    "df_2D = df[df['study_id'].str.contains('2D', case=False)].copy()\n",
    "df_3D = df[df['study_id'].str.contains('3D', case=False)].copy()\n",
    "\n",
    "# Step 3: Find common subjects\n",
    "common_ids = set(df_2D['file_id']) & set(df_3D['file_id'])\n",
    "\n",
    "print(f\"Found {len(common_ids)} studies with both 2D and 3D\")\n",
    "\n",
    "# Step 4: Compare labels for each common subject\n",
    "inconsistent_cases = []\n",
    "\n",
    "for file_id in sorted(common_ids):\n",
    "    row_2d = df_2D[df_2D['file_id'] == file_id].iloc[0]\n",
    "    row_3d = df_3D[df_3D['file_id'] == file_id].iloc[0]\n",
    "\n",
    "    diffs = {}\n",
    "    for col in ['us_effusion', 'xr_effusion', 'us_fracture', 'xr_fracture']:\n",
    "        if row_2d[col] != row_3d[col]:\n",
    "            diffs[col] = (row_2d[col], row_3d[col])\n",
    "\n",
    "    if diffs:\n",
    "        inconsistent_cases.append({\n",
    "            'file_id': file_id,\n",
    "            'differences': diffs\n",
    "        })\n",
    "\n",
    "# Step 5: Print mismatches\n",
    "if inconsistent_cases:\n",
    "    print(\"Inconsistent labeling found for the following studies:\")\n",
    "    for case in inconsistent_cases:\n",
    "        print(f\"Study {case['file_id']}:\")\n",
    "        for label, (v2d, v3d) in case['differences'].items():\n",
    "            print(f\"  - {label}: 2D = {v2d}, 3D = {v3d}\")\n",
    "else:\n",
    "    print(\"All common studies have consistent labeling between 2D and 3D\")\n",
    "\n",
    "print('Number of inconsistent cases:', len(inconsistent_cases))    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d62668b",
   "metadata": {},
   "source": [
    "- Of the 52 subjects with both 2D and 3D scans, 19 show label inconsistencies, primarily in us_fracture and us_effusion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c224d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D dor shape: (1024, 768, 165)\n",
      "2D vul shape: (1024, 768, 99)\n",
      "3D dor shape: (800, 600, 127)\n",
      "3D vul shape: (800, 600, 127)\n",
      "2d dor labels: [0. 1. 2. 4. 6.]\n",
      "2d vul labels: [0. 1. 4. 6.]\n",
      "3d dor labels: [0. 1. 2. 4.]\n",
      "3d vul labels: [0. 1. 4.]\n"
     ]
    }
   ],
   "source": [
    "file_2d_dor = nib.load(r\"B:\\US_Data_backup\\Elbow Data\\2D Lumify Elbow Data\\_2D Lumify Elbow Data\\88023 elbow 2D\\88023-right-elbow-dor.nii.gz\").get_fdata()\n",
    "file_2d_vul = nib.load(r\"B:\\US_Data_backup\\Elbow Data\\2D Lumify Elbow Data\\_2D Lumify Elbow Data\\88023 elbow 2D\\88023-right-elbow-vul.nii.gz\").get_fdata()\n",
    "\n",
    "file_3d_dor = nib.load(r\"B:\\US_Data_backup\\Elbow Data\\3D iU22 Elbow Data\\_3D iU22 Elbow Data\\88023 elbow 3D\\88023-right-elbow-dor.nii.gz\").get_fdata()\n",
    "file_3d_vul = nib.load(r\"B:\\US_Data_backup\\Elbow Data\\3D iU22 Elbow Data\\_3D iU22 Elbow Data\\88023 elbow 3D\\88023-right-elbow-vul.nii.gz\").get_fdata()\n",
    "\n",
    "print(\"2D dor shape:\", file_2d_dor.shape)\n",
    "print(\"2D vul shape:\", file_2d_vul.shape)\n",
    "print(\"3D dor shape:\", file_3d_dor.shape)\n",
    "print(\"3D vul shape:\", file_3d_vul.shape)\n",
    "\n",
    "print(\"2d dor labels:\", np.unique(file_2d_dor))\n",
    "print(\"2d vul labels:\", np.unique(file_2d_vul))\n",
    "print(\"3d dor labels:\", np.unique(file_3d_dor))\n",
    "print(\"3d vul labels:\", np.unique(file_3d_vul))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea145de",
   "metadata": {},
   "source": [
    "- Of the 52 subjects with both 2D and 3D scans, 19 show label inconsistencies, primarily in us_fracture and us_effusion. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165881ea",
   "metadata": {},
   "source": [
    "## Diagnostic Performance Analysis\n",
    "\n",
    "In this section, we evaluate the diagnostic accuracy of ultrasound (US) in detecting elbow **fractures** and **joint effusions**, using X-ray (XR) as the reference standard (ground truth). The analysis is limited to the **52 subjects** who underwent **both 2D and 3D ultrasound** imaging.\n",
    "\n",
    "We assess performance using the following metrics:\n",
    "- **Sensitivity (Recall)**: How well US detects XR-confirmed positives (fractures or effusions).\n",
    "- **Specificity**: How well US avoids false positives when XR is normal.\n",
    "- **Positive Predictive Value (PPV)**: Probability that a positive US finding is truly positive.\n",
    "- **Negative Predictive Value (NPV)**: Probability that a negative US finding is truly negative.\n",
    "\n",
    "The comparison is performed **separately** for:\n",
    "- **2D US vs XR**\n",
    "- **3D US vs XR**\n",
    "\n",
    "The following evaluations are conducted:\n",
    "- **Fracture detection using US compared to XR**\n",
    "- **Effusion detection using US compared to XR**\n",
    "- **Fracture detection using US detected effusion**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1dd7f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure `file_id` column is defined\n",
    "df['file_id'] = df['study_id'].str.extract(r'(W\\d{5}|\\d{5})', expand=False).str.upper()\n",
    "\n",
    "# Separate 2D and 3D entries\n",
    "df_2D = df[df['study_id'].str.contains('2D', case=False)].copy()\n",
    "df_3D = df[df['study_id'].str.contains('3D', case=False)].copy()\n",
    "\n",
    "# Identify common IDs\n",
    "common_ids = set(df_2D['file_id']) & set(df_3D['file_id'])\n",
    "\n",
    "# Filter to just the 52 common subjects\n",
    "df_2D_common = df_2D[df_2D['file_id'].isin(common_ids)].copy()\n",
    "df_3D_common = df_3D[df_3D['file_id'].isin(common_ids)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6be1c39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_counts(pred, truth):\n",
    "    \"\"\"Return TP, FP, TN, FN counts given two equal-length 0/1 arrays.\"\"\"\n",
    "    tp = ((pred == 1) & (truth == 1)).sum()\n",
    "    fp = ((pred == 1) & (truth == 0)).sum()\n",
    "    tn = ((pred == 0) & (truth == 0)).sum()\n",
    "    fn = ((pred == 0) & (truth == 1)).sum()\n",
    "    return tp, fp, tn, fn\n",
    "\n",
    "def metrics(tp, fp, tn, fn):\n",
    "    sens = tp / (tp + fn) if (tp + fn) else float(\"nan\")\n",
    "    spec = tn / (tn + fp) if (tn + fp) else float(\"nan\")\n",
    "    ppv  = tp / (tp + fp) if (tp + fp) else float(\"nan\")\n",
    "    npv  = tn / (tn + fn) if (tn + fn) else float(\"nan\")\n",
    "    return sens, spec, ppv, npv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca8771d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(name, df, pred_col, truth_col):\n",
    "    tp, fp, tn, fn = confusion_counts(df[pred_col], df[truth_col])\n",
    "    sens, spec, ppv, npv = metrics(tp, fp, tn, fn)\n",
    "    total = len(df)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Sample size: {total} cases\")\n",
    "    print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "    print(f\"Sensitivity (recall): {sens:.3f}\")\n",
    "    print(f\"Specificity:          {spec:.3f}\")\n",
    "    print(f\"PPV (precision):      {ppv:.3f}\")\n",
    "    print(f\"NPV:                  {npv:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb799c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 2D US Effusion vs XR Effusion ===\n",
      "Sample size: 52 cases\n",
      "TP=24, FP=8, TN=15, FN=5\n",
      "Sensitivity (recall): 0.828\n",
      "Specificity:          0.652\n",
      "PPV (precision):      0.750\n",
      "NPV:                  0.750\n",
      "\n",
      "=== 3D US Effusion vs XR Effusion ===\n",
      "Sample size: 52 cases\n",
      "TP=22, FP=3, TN=20, FN=7\n",
      "Sensitivity (recall): 0.759\n",
      "Specificity:          0.870\n",
      "PPV (precision):      0.880\n",
      "NPV:                  0.741\n"
     ]
    }
   ],
   "source": [
    "# A. Effusion (US) vs Effusion (XR) on 2D\n",
    "show_results(\"2D US Effusion vs XR Effusion\", df_2D_common, \"us_effusion\", \"xr_effusion\")\n",
    "# Effusion (US) vs Effusion (XR) on 3D\n",
    "show_results(\"3D US Effusion vs XR Effusion\", df_3D_common, \"us_effusion\", \"xr_effusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6fa9bbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 2D US Fracture vs XR Fracture ===\n",
      "Sample size: 52 cases\n",
      "TP=10, FP=13, TN=26, FN=3\n",
      "Sensitivity (recall): 0.769\n",
      "Specificity:          0.667\n",
      "PPV (precision):      0.435\n",
      "NPV:                  0.897\n",
      "\n",
      "=== 3D US Fracture vs XR Fracture ===\n",
      "Sample size: 52 cases\n",
      "TP=9, FP=6, TN=33, FN=4\n",
      "Sensitivity (recall): 0.692\n",
      "Specificity:          0.846\n",
      "PPV (precision):      0.600\n",
      "NPV:                  0.892\n"
     ]
    }
   ],
   "source": [
    "# B. Fracture (US) vs Fracture (XR) on 2D\n",
    "show_results(\"2D US Fracture vs XR Fracture\", df_2D_common, \"us_fracture\", \"xr_fracture\")\n",
    "\n",
    "# Evaluate fracture detection (US vs XR) on 3D\n",
    "show_results(\"3D US Fracture vs XR Fracture\", df_3D_common, \"us_fracture\", \"xr_fracture\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0ca3ca67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 2D US Effusion vs XR Fracture ===\n",
      "Sample size: 52 cases\n",
      "TP=12, FP=20, TN=19, FN=1\n",
      "Sensitivity (recall): 0.923\n",
      "Specificity:          0.487\n",
      "PPV (precision):      0.375\n",
      "NPV:                  0.950\n",
      "\n",
      "=== 3D US Effusion vs XR Fracture ===\n",
      "Sample size: 52 cases\n",
      "TP=12, FP=13, TN=26, FN=1\n",
      "Sensitivity (recall): 0.923\n",
      "Specificity:          0.667\n",
      "PPV (precision):      0.480\n",
      "NPV:                  0.963\n"
     ]
    }
   ],
   "source": [
    "# C. Effusion (US) predicting Fracture (XR) on 2D\n",
    "show_results(\"2D US Effusion vs XR Fracture\", df_2D_common, \"us_effusion\", \"xr_fracture\")\n",
    "# Effusion (US) predicting Fracture (XR) on 3D\n",
    "show_results(\"3D US Effusion vs XR Fracture\", df_3D_common, \"us_effusion\", \"xr_fracture\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9872d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def get_all_labels_in_folder(folder_path, include_subfolders=True):\n",
    "    folder = Path(folder_path)\n",
    "    ext = [\".nii\", \".nii.gz\"]\n",
    "    all_labels = set()\n",
    "\n",
    "    if include_subfolders:\n",
    "        nifti_files = list(folder.rglob(\"*\"))  # recursive\n",
    "    else:\n",
    "        nifti_files = list(folder.glob(\"*\"))   # only top level\n",
    "\n",
    "    nifti_files = [f for f in nifti_files if f.suffix in ext or f.suffixes == [\".nii\", \".gz\"]]\n",
    "\n",
    "    print(f\"Found {len(nifti_files)} NIfTI files.\\n\")\n",
    "\n",
    "    for f in nifti_files:\n",
    "        try:\n",
    "            img = nib.load(str(f))\n",
    "            data = img.get_fdata()\n",
    "            labels = np.unique(data)\n",
    "            labels = labels.astype(int) if np.all(labels == labels.astype(int)) else labels\n",
    "            print(f\"{f.name}: Labels = {labels}\")\n",
    "            all_labels.update(labels.tolist())\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {f.name}: {e}\")\n",
    "\n",
    "    print(\"\\n=== All unique labels across folder ===\")\n",
    "    print(sorted(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ba9e341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 130 NIfTI files.\n",
      "\n",
      "88010-left-elbow-dor.nii.gz: Labels = [0 1 2]\n",
      "88010-left-elbow-vul.nii.gz: Labels = [0 1 4]\n",
      "88015-left-elbow-dor.nii.gz: Labels = [0 1 2 4 6]\n",
      "88015-left-elbow-vul.nii.gz: Labels = [0 1 6]\n",
      "88017-right-elbow-dor.nii.gz: Labels = [0 1]\n",
      "88017-right-elbow-dor2.nii.gz: Labels = [0 1 2 4]\n",
      "88017-right-elbow-vul.nii.gz: Labels = [0 1 3 4]\n",
      "88019-right-elbow-dor.nii.gz: Labels = [0 1 2 4 6]\n",
      "88019-right-elbow-vul.nii.gz: Labels = [0 1 4 6]\n",
      "88022-left-elbow-dor.nii.gz: Labels = [0 1 4 6]\n",
      "88022-left-elbow-vul.nii.gz: Labels = [0 1 2 3 4]\n",
      "88023-right-elbow-dor.nii.gz: Labels = [0 1 2 4 6]\n",
      "88023-right-elbow-vul.nii.gz: Labels = [0 1 4 6]\n",
      "88025-right-elbow-vul.nii.gz: Labels = [0 1 2 3 4 6]\n",
      "88026-right-elbow-dor.nii.gz: Labels = [0 1]\n",
      "88026-right-elbow-vul.nii.gz: Labels = [0 1 4 6]\n",
      "88028-left-elbow-dor.nii.gz: Labels = [0 1 2 4 6]\n",
      "88028-left-elbow-vul.nii.gz: Labels = [0 1 2 3 4 6]\n",
      "88033-left-elbow-dor.nii.gz: Labels = [0 1 2 4]\n",
      "88033-left-elbow-vul.nii.gz: Labels = [0 1 2 3 4]\n",
      "88034-right-elbow-dor.nii.gz: Labels = [0 1 2 4]\n",
      "88034-right-elbow-vul.nii.gz: Labels = [0 1 3 4]\n",
      "88036-left-elbow-dor.nii.gz: Labels = [0 1 2 4 5 6]\n",
      "88036-left-elbow-vul.nii.gz: Labels = [0 1 2 3 4 6]\n",
      "88037-left-elbow-dor.nii.gz: Labels = [0 1 2 4 5 6]\n",
      "88049-right-elbow-dor.nii.gz: Labels = [0 1 2]\n",
      "88049-right-elbow-vul.nii.gz: Labels = [0 1 4]\n",
      "88055-right-elbow-dor.nii.gz: Labels = [0 1 2]\n",
      "88055-right-elbow-vul.nii.gz: Labels = [0 1 3 4]\n",
      "88057-left-elbow-dor.nii.gz: Labels = [0 1 2]\n",
      "88057-left-elbow-vul.nii.gz: Labels = [0 1 2 3 4]\n",
      "88058-right-elbow-dor.nii.gz: Labels = [0 1 5]\n",
      "88058-right-elbow-vul.nii.gz: Labels = [0 1 2 3 4]\n",
      "88061-right-elbow-dor.nii.gz: Labels = [0 1 2]\n",
      "88061-right-elbow-vul.nii.gz: Labels = [0 1 4]\n",
      "88068-left-elbow-dor.nii.gz: Labels = [0 1 2 4]\n",
      "88068-left-elbow-vul.nii.gz: Labels = [0 1 2 4]\n",
      "88069-left-elbow-dor.nii.gz: Labels = [0 1 2 4 5 6]\n",
      "88069-left-elbow-vul.nii.gz: Labels = [0 1 3 4 6]\n",
      "88070-left-elbow-dor.nii.gz: Labels = [0 1 4]\n",
      "88070-left-elbow-vul.nii.gz: Labels = [0 1 3 4]\n",
      "88072-left-elbow-dor.nii.gz: Labels = [0 1 5 6]\n",
      "88072-left-elbow-vul.nii.gz: Labels = [0 1 3 4 6]\n",
      "88074-left-elbow-dor.nii.gz: Labels = [0 1 2 4 6]\n",
      "88074-left-elbow-vul.nii.gz: Labels = [0 1 4]\n",
      "88075-right-elbow-dor.nii.gz: Labels = [0 1 2 4 7]\n",
      "88075-right-elbow-vul.nii.gz: Labels = [0 1 2 3 4 6]\n",
      "88077-left-elbow-dor.nii.gz: Labels = [0 1 2 4]\n",
      "88077-left-elbow-vul.nii.gz: Labels = [0 1 4]\n",
      "88078-left-elbow-dor.nii.gz: Labels = [0 1 2 4 5 6]\n",
      "88078-left-elbow-vul.nii.gz: Labels = [0 1 3 4 6]\n",
      "88082-right-elbow-dor.nii.gz: Labels = [0 1 4]\n",
      "88082-right-elbow-vul.nii.gz: Labels = [0 1 2 4 6]\n",
      "88084-left-elbow-dor.nii.gz: Labels = [0 1 2 4 6]\n",
      "88084-left-elbow-vul.nii.gz: Labels = [0 1 3 4]\n",
      "88090-left-elbow-dor.nii.gz: Labels = [0 1 2 4 5 6 7]\n",
      "88090-left-elbow-vul.nii.gz: Labels = [0 1 4 6]\n",
      "88091-right-elbow-dor.nii.gz: Labels = [0 1 2 4 6]\n",
      "88091-right-elbow-vul.nii.gz: Labels = [0 1 2 3 4]\n",
      "88094-right-elbow-dor.nii.gz: Labels = [0 1 4 6 7]\n",
      "88094-right-elbow-vul.nii.gz: Labels = [0 1 3 4 6 7]\n",
      "88095-right-elbow-dor.nii.gz: Labels = [0 1 2 4]\n",
      "88095-right-elbow-vul.nii.gz: Labels = [0 1 3 4]\n",
      "88096-right-elbow-dor.nii.gz: Labels = [0 1 4]\n",
      "88096-right-elbow-vul.nii.gz: Labels = [0 1 3 4]\n",
      "88097-right-elbow-dor.nii.gz: Labels = [0 1 3 6]\n",
      "88097-right-elbow-vul.nii.gz: Labels = [0 1 2 4 6]\n",
      "88098-left-elbow-dor.nii.gz: Labels = [0 1 6 7]\n",
      "88098-left-elbow-vul.nii.gz: Labels = [0 1 4 6 7]\n",
      "88099-left-elbow-dor.nii.gz: Labels = [0 1 2 4 5 6]\n",
      "88099-left-elbow-vul.nii.gz: Labels = [0 1 3 4 6]\n",
      "88102-left-elbow-dor.nii.gz: Labels = [0 1 2 3]\n",
      "88102-left-elbow-vul.nii.gz: Labels = [0 1 3 4]\n",
      "88105-right-elbow-dor.nii.gz: Labels = [0 1 2]\n",
      "88105-right-elbow-vul.nii.gz: Labels = [0 1 4]\n",
      "88106-right-elbow-dor.nii.gz: Labels = [0 1 2 6]\n",
      "88106-right-elbow-vul.nii.gz: Labels = [0 1 4 6]\n",
      "88111-right-elbow-dor.nii.gz: Labels = [0 1 2 4 6]\n",
      "88111-right-elbow-vul.nii.gz: Labels = [0 1 2 3 4 6]\n",
      "88112-left-elbow-dor.nii.gz: Labels = [0 1 2 4]\n",
      "88114-right-elbow-dor.nii.gz: Labels = [0 1 5 6 7]\n",
      "88114-right-elbow-vul.nii.gz: Labels = [0 1 4 6 7]\n",
      "88118-right-elbow-dor.nii.gz: Labels = [0 1 2 4 6]\n",
      "88118-right-elbow-vul.nii.gz: Labels = [0 1 3 4 6]\n",
      "88119-right-elbow-dor.nii.gz: Labels = [0 1 2 4 6]\n",
      "88119-right-elbow-vul.nii.gz: Labels = [0 1 3 4 6]\n",
      "88122-left-elbow-dor.nii.gz: Labels = [0 1 2 4 5 6]\n",
      "88122-left-elbow-vul.nii.gz: Labels = [0 1 3 4 6]\n",
      "88126-right-elbow-dor.nii.gz: Labels = [0 1 2 4 6]\n",
      "88126-right-elbow-vul.nii.gz: Labels = [0 1 4 6]\n",
      "88128-left-elbow-dor.nii.gz: Labels = [0 1 2 4]\n",
      "88128-left-elbow-vul.nii.gz: Labels = [0 1 3 4]\n",
      "88131-right-elbow-dor.nii.gz: Labels = [0 1 2 4 6]\n",
      "88131-right-elbow-vul.nii.gz: Labels = [0 1 3 4 6]\n",
      "88132-left-elbow-dor.nii.gz: Labels = [0 1 2 4 6]\n",
      "88132-left-elbow-vul.nii.gz: Labels = [0 1 3 4 6]\n",
      "88133-left-elbow-dor.nii.gz: Labels = [0 1 4]\n",
      "88133-left-elbow-vul.nii.gz: Labels = [0 1 3 4]\n",
      "88135-right-elbow-dor.nii.gz: Labels = [0 1 2 6]\n",
      "88135-right-elbow-vul.nii.gz: Labels = [0 1 3 4 6 7]\n",
      "88137-right-elbow-dor.nii.gz: Labels = [0 1 2 4 5]\n",
      "88137-right-elbow-vul.nii.gz: Labels = [0 1 2 3 4 6]\n",
      "88138-right-elbow-dor.nii.gz: Labels = [0 1 2]\n",
      "88138-right-elbow-vul.nii.gz: Labels = [0 1 3 4]\n",
      "88141-right-elbow-dor.nii.gz: Labels = [0 1 2 4 6]\n",
      "88141-right-elbow-vul.nii.gz: Labels = [0 1 2 3 4 6]\n",
      "88145-right-elbow-dor.nii.gz: Labels = [0 1 4 6 7]\n",
      "88148-right-elbow-dor.nii.gz: Labels = [0 1 6 7]\n",
      "88148-right-elbow-vul.nii.gz: Labels = [0 1 2 3 4 6]\n",
      "88150-right-elbow-dor.nii.gz: Labels = [0 1 2 4 5 6]\n",
      "88150-right-elbow-vul.nii.gz: Labels = [0 1 4 6 7]\n",
      "88152-right-elbow-dor.nii.gz: Labels = [0 1 4 6]\n",
      "88152-right-elbow-vul.nii.gz: Labels = [0 1 4 6]\n",
      "88154-left-elbow-dor.nii.gz: Labels = [0 1 2 4 6]\n",
      "88154-left-elbow-vul.nii.gz: Labels = [0 1 2 3 4 6]\n",
      "88156-right-elbow-dor.nii.gz: Labels = [0 1 2 4]\n",
      "88156-right-elbow-vul.nii.gz: Labels = [0 1 4 6]\n",
      "88158-right-elbow-dor.nii.gz: Labels = [0 1 2 4 6]\n",
      "88158-right-elbow-vul.nii.gz: Labels = [0 1 2 3 4]\n",
      "88159-right-elbow-dor.nii.gz: Labels = [0 1 2 4]\n",
      "88159-right-wrist-vul.nii.gz: Labels = [0 1 2 3 4]\n",
      "88162-left-elbow-dor.nii.gz: Labels = [0 1 2 5 6]\n",
      "88162-left-elbow-vul.nii.gz: Labels = [0 1 3 4]\n",
      "88170-left-elbow-dor.nii.gz: Labels = [0 1 4 5]\n",
      "88172-right-elbow-dor.nii.gz: Labels = [0 1 4]\n",
      "88172-right-elbow-vul.nii.gz: Labels = [0 1 2 3 4]\n",
      "W00001-right-elbow-dor.nii.gz: Labels = [0 1 6]\n",
      "W00001-right-elbow-vul.nii.gz: Labels = [0 1 4 6]\n",
      "W00008-left-elbow-dor.nii.gz: Labels = [0 1 2 4 6]\n",
      "W00008-left-elbow-vul.nii.gz: Labels = [0 1 4 6]\n",
      "\n",
      "=== All unique labels across folder ===\n",
      "[0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "get_all_labels_in_folder(r\"M:\\ElbowProject\\data\\_2D Lumify Elbow Data\\masks\", include_subfolders=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "13a9c00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦴 Found 12 files with label 7:\n",
      " - 88075-right-elbow-dor.nii.gz\n",
      " - 88090-left-elbow-dor.nii.gz\n",
      " - 88094-right-elbow-dor.nii.gz\n",
      " - 88094-right-elbow-vul.nii.gz\n",
      " - 88098-left-elbow-dor.nii.gz\n",
      " - 88098-left-elbow-vul.nii.gz\n",
      " - 88114-right-elbow-dor.nii.gz\n",
      " - 88114-right-elbow-vul.nii.gz\n",
      " - 88135-right-elbow-vul.nii.gz\n",
      " - 88145-right-elbow-dor.nii.gz\n",
      " - 88148-right-elbow-dor.nii.gz\n",
      " - 88150-right-elbow-vul.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def get_files_with_label_7(mask_folder):\n",
    "    mask_folder = Path(mask_folder)\n",
    "    files_with_label_7 = []\n",
    "\n",
    "    for nii_file in mask_folder.glob(\"*.nii*\"):\n",
    "        try:\n",
    "            mask = nib.load(nii_file).get_fdata().astype(np.uint8)\n",
    "            if 7 in np.unique(mask):\n",
    "                files_with_label_7.append(nii_file.name)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error reading {nii_file.name}: {e}\")\n",
    "\n",
    "    return files_with_label_7\n",
    "fracture_cases = get_files_with_label_7(\n",
    "    r\"M:\\ElbowProject\\data\\_2D Lumify Elbow Data\\masks\"\n",
    ")\n",
    "\n",
    "print(f\"🦴 Found {len(fracture_cases)} files with label 7:\")\n",
    "for f in fracture_cases:\n",
    "    print(f\" - {f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e1df4593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['88075', '88090', '88094', '88098', '88114', '88135', '88145', '88148', '88150']\n"
     ]
    }
   ],
   "source": [
    "# Extract unique IDs\n",
    "ids = sorted({re.match(r'^\\d+', name).group() for name in fracture_cases})\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "36143616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['88023', '88025', '88026', '88034', '88037', '88068', '88072', '88074', '88090', '88094', '88098', '88099', '88114', '88118', '88119', '88122', '88132', '88138', '88145', '88148', '88150', '88152', '88162']\n"
     ]
    }
   ],
   "source": [
    "# Filter rows with US fracture = 1\n",
    "df_2D_fx = df_2D_common[df_2D_common['us_fracture'] == 1]\n",
    "\n",
    "# Extract unique alphanumeric file IDs\n",
    "fx_ids_2D = sorted(df_2D_fx['file_id'].unique())\n",
    "\n",
    "print(fx_ids_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6cea05f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fracture labeled on the masks but labeled no fracture in the spread sheet: ['88075', '88135']\n",
      "fracture in the spread sheet  but has no fracture label (7) in the segmentation mask ['88023', '88025', '88026', '88034', '88037', '88068', '88072', '88074', '88099', '88118', '88119', '88122', '88132', '88138', '88152', '88162']\n"
     ]
    }
   ],
   "source": [
    "only_in_list1 = sorted(set(ids) - set(fx_ids_2D))\n",
    "only_in_list2 = sorted(set(fx_ids_2D) - set(ids))\n",
    "\n",
    "print(\"fracture labeled on the masks but labeled no fracture in the spread sheet:\", only_in_list1)\n",
    "print(\"fracture in the spread sheet  but has no fracture label (7) in the segmentation mask\", only_in_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5e404d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦴 Found 74 files with label 6:\n",
      " - 88015-left-elbow-dor.nii.gz\n",
      " - 88015-left-elbow-vul.nii.gz\n",
      " - 88019-right-elbow-dor.nii.gz\n",
      " - 88019-right-elbow-vul.nii.gz\n",
      " - 88022-left-elbow-dor.nii.gz\n",
      " - 88023-right-elbow-dor.nii.gz\n",
      " - 88023-right-elbow-vul.nii.gz\n",
      " - 88025-right-elbow-vul.nii.gz\n",
      " - 88026-right-elbow-vul.nii.gz\n",
      " - 88028-left-elbow-dor.nii.gz\n",
      " - 88028-left-elbow-vul.nii.gz\n",
      " - 88036-left-elbow-dor.nii.gz\n",
      " - 88036-left-elbow-vul.nii.gz\n",
      " - 88037-left-elbow-dor.nii.gz\n",
      " - 88069-left-elbow-dor.nii.gz\n",
      " - 88069-left-elbow-vul.nii.gz\n",
      " - 88072-left-elbow-dor.nii.gz\n",
      " - 88072-left-elbow-vul.nii.gz\n",
      " - 88074-left-elbow-dor.nii.gz\n",
      " - 88075-right-elbow-vul.nii.gz\n",
      " - 88078-left-elbow-dor.nii.gz\n",
      " - 88078-left-elbow-vul.nii.gz\n",
      " - 88082-right-elbow-vul.nii.gz\n",
      " - 88084-left-elbow-dor.nii.gz\n",
      " - 88090-left-elbow-dor.nii.gz\n",
      " - 88090-left-elbow-vul.nii.gz\n",
      " - 88091-right-elbow-dor.nii.gz\n",
      " - 88094-right-elbow-dor.nii.gz\n",
      " - 88094-right-elbow-vul.nii.gz\n",
      " - 88097-right-elbow-dor.nii.gz\n",
      " - 88097-right-elbow-vul.nii.gz\n",
      " - 88098-left-elbow-dor.nii.gz\n",
      " - 88098-left-elbow-vul.nii.gz\n",
      " - 88099-left-elbow-dor.nii.gz\n",
      " - 88099-left-elbow-vul.nii.gz\n",
      " - 88106-right-elbow-dor.nii.gz\n",
      " - 88106-right-elbow-vul.nii.gz\n",
      " - 88111-right-elbow-dor.nii.gz\n",
      " - 88111-right-elbow-vul.nii.gz\n",
      " - 88114-right-elbow-dor.nii.gz\n",
      " - 88114-right-elbow-vul.nii.gz\n",
      " - 88118-right-elbow-dor.nii.gz\n",
      " - 88118-right-elbow-vul.nii.gz\n",
      " - 88119-right-elbow-dor.nii.gz\n",
      " - 88119-right-elbow-vul.nii.gz\n",
      " - 88122-left-elbow-dor.nii.gz\n",
      " - 88122-left-elbow-vul.nii.gz\n",
      " - 88126-right-elbow-dor.nii.gz\n",
      " - 88126-right-elbow-vul.nii.gz\n",
      " - 88131-right-elbow-dor.nii.gz\n",
      " - 88131-right-elbow-vul.nii.gz\n",
      " - 88132-left-elbow-dor.nii.gz\n",
      " - 88132-left-elbow-vul.nii.gz\n",
      " - 88135-right-elbow-dor.nii.gz\n",
      " - 88135-right-elbow-vul.nii.gz\n",
      " - 88137-right-elbow-vul.nii.gz\n",
      " - 88141-right-elbow-dor.nii.gz\n",
      " - 88141-right-elbow-vul.nii.gz\n",
      " - 88145-right-elbow-dor.nii.gz\n",
      " - 88148-right-elbow-dor.nii.gz\n",
      " - 88148-right-elbow-vul.nii.gz\n",
      " - 88150-right-elbow-dor.nii.gz\n",
      " - 88150-right-elbow-vul.nii.gz\n",
      " - 88152-right-elbow-dor.nii.gz\n",
      " - 88152-right-elbow-vul.nii.gz\n",
      " - 88154-left-elbow-dor.nii.gz\n",
      " - 88154-left-elbow-vul.nii.gz\n",
      " - 88156-right-elbow-vul.nii.gz\n",
      " - 88158-right-elbow-dor.nii.gz\n",
      " - 88162-left-elbow-dor.nii.gz\n",
      " - W00001-right-elbow-dor.nii.gz\n",
      " - W00001-right-elbow-vul.nii.gz\n",
      " - W00008-left-elbow-dor.nii.gz\n",
      " - W00008-left-elbow-vul.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def get_files_with_label_6(mask_folder):\n",
    "    mask_folder = Path(mask_folder)\n",
    "    files_with_label_6 = []\n",
    "\n",
    "    for nii_file in mask_folder.glob(\"*.nii*\"):\n",
    "        try:\n",
    "            mask = nib.load(nii_file).get_fdata().astype(np.uint8)\n",
    "            if 6 in np.unique(mask):\n",
    "                files_with_label_6.append(nii_file.name)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error reading {nii_file.name}: {e}\")\n",
    "\n",
    "    return files_with_label_6\n",
    "effusion_cases = get_files_with_label_6(\n",
    "    r\"M:\\ElbowProject\\data\\_2D Lumify Elbow Data\\masks\"\n",
    ")\n",
    "\n",
    "print(f\"🦴 Found {len(effusion_cases)} files with label 6:\")\n",
    "for f in effusion_cases:\n",
    "    print(f\" - {f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "abcd5a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['88015-left-elbow-dor.nii.gz',\n",
       " '88015-left-elbow-vul.nii.gz',\n",
       " '88019-right-elbow-dor.nii.gz',\n",
       " '88019-right-elbow-vul.nii.gz',\n",
       " '88022-left-elbow-dor.nii.gz',\n",
       " '88023-right-elbow-dor.nii.gz',\n",
       " '88023-right-elbow-vul.nii.gz',\n",
       " '88025-right-elbow-vul.nii.gz',\n",
       " '88026-right-elbow-vul.nii.gz',\n",
       " '88028-left-elbow-dor.nii.gz',\n",
       " '88028-left-elbow-vul.nii.gz',\n",
       " '88036-left-elbow-dor.nii.gz',\n",
       " '88036-left-elbow-vul.nii.gz',\n",
       " '88037-left-elbow-dor.nii.gz',\n",
       " '88069-left-elbow-dor.nii.gz',\n",
       " '88069-left-elbow-vul.nii.gz',\n",
       " '88072-left-elbow-dor.nii.gz',\n",
       " '88072-left-elbow-vul.nii.gz',\n",
       " '88074-left-elbow-dor.nii.gz',\n",
       " '88075-right-elbow-vul.nii.gz',\n",
       " '88078-left-elbow-dor.nii.gz',\n",
       " '88078-left-elbow-vul.nii.gz',\n",
       " '88082-right-elbow-vul.nii.gz',\n",
       " '88084-left-elbow-dor.nii.gz',\n",
       " '88090-left-elbow-dor.nii.gz',\n",
       " '88090-left-elbow-vul.nii.gz',\n",
       " '88091-right-elbow-dor.nii.gz',\n",
       " '88094-right-elbow-dor.nii.gz',\n",
       " '88094-right-elbow-vul.nii.gz',\n",
       " '88097-right-elbow-dor.nii.gz',\n",
       " '88097-right-elbow-vul.nii.gz',\n",
       " '88098-left-elbow-dor.nii.gz',\n",
       " '88098-left-elbow-vul.nii.gz',\n",
       " '88099-left-elbow-dor.nii.gz',\n",
       " '88099-left-elbow-vul.nii.gz',\n",
       " '88106-right-elbow-dor.nii.gz',\n",
       " '88106-right-elbow-vul.nii.gz',\n",
       " '88111-right-elbow-dor.nii.gz',\n",
       " '88111-right-elbow-vul.nii.gz',\n",
       " '88114-right-elbow-dor.nii.gz',\n",
       " '88114-right-elbow-vul.nii.gz',\n",
       " '88118-right-elbow-dor.nii.gz',\n",
       " '88118-right-elbow-vul.nii.gz',\n",
       " '88119-right-elbow-dor.nii.gz',\n",
       " '88119-right-elbow-vul.nii.gz',\n",
       " '88122-left-elbow-dor.nii.gz',\n",
       " '88122-left-elbow-vul.nii.gz',\n",
       " '88126-right-elbow-dor.nii.gz',\n",
       " '88126-right-elbow-vul.nii.gz',\n",
       " '88131-right-elbow-dor.nii.gz',\n",
       " '88131-right-elbow-vul.nii.gz',\n",
       " '88132-left-elbow-dor.nii.gz',\n",
       " '88132-left-elbow-vul.nii.gz',\n",
       " '88135-right-elbow-dor.nii.gz',\n",
       " '88135-right-elbow-vul.nii.gz',\n",
       " '88137-right-elbow-vul.nii.gz',\n",
       " '88141-right-elbow-dor.nii.gz',\n",
       " '88141-right-elbow-vul.nii.gz',\n",
       " '88145-right-elbow-dor.nii.gz',\n",
       " '88148-right-elbow-dor.nii.gz',\n",
       " '88148-right-elbow-vul.nii.gz',\n",
       " '88150-right-elbow-dor.nii.gz',\n",
       " '88150-right-elbow-vul.nii.gz',\n",
       " '88152-right-elbow-dor.nii.gz',\n",
       " '88152-right-elbow-vul.nii.gz',\n",
       " '88154-left-elbow-dor.nii.gz',\n",
       " '88154-left-elbow-vul.nii.gz',\n",
       " '88156-right-elbow-vul.nii.gz',\n",
       " '88158-right-elbow-dor.nii.gz',\n",
       " '88162-left-elbow-dor.nii.gz',\n",
       " 'W00001-right-elbow-dor.nii.gz',\n",
       " 'W00001-right-elbow-vul.nii.gz',\n",
       " 'W00008-left-elbow-dor.nii.gz',\n",
       " 'W00008-left-elbow-vul.nii.gz']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effusion_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5d8f8c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['88015', '88019', '88022', '88023', '88025', '88026', '88028', '88036', '88037', '88069', '88072', '88074', '88075', '88078', '88082', '88084', '88090', '88091', '88094', '88097', '88098', '88099', '88106', '88111', '88114', '88118', '88119', '88122', '88126', '88131', '88132', '88135', '88137', '88141', '88145', '88148', '88150', '88152', '88154', '88156', '88158', '88162', 'W00001', 'W00008']\n"
     ]
    }
   ],
   "source": [
    "# Extract unique alphanumeric IDs (e.g., W00008 or 88075)\n",
    "ids_effusion = sorted({re.match(r'^(W\\d{5}|\\d{5})', name).group().upper() for name in effusion_cases})\n",
    "print(ids_effusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "89851043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['88015', '88022', '88023', '88025', '88026', '88033', '88034', '88037', '88072', '88074', '88075', '88078', '88090', '88091', '88094', '88098', '88099', '88106', '88114', '88118', '88119', '88122', '88132', '88135', '88138', '88141', '88145', '88150', '88152', '88154', '88158', '88162']\n"
     ]
    }
   ],
   "source": [
    "# Filter rows with US fracture = 1\n",
    "df_2D_effusion = df_2D_common[df_2D_common['us_effusion'] == 1]\n",
    "\n",
    "# Extract unique alphanumeric file IDs\n",
    "df_2D_effusion = sorted(df_2D_effusion['file_id'].unique())\n",
    "\n",
    "print(df_2D_effusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f833f79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "effusion labeled on the masks but labeled no effusion in the spread sheet: ['88019', '88028', '88036', '88069', '88082', '88084', '88097', '88111', '88126', '88131', '88137', '88148', '88156', 'W00001', 'W00008']\n",
      "effusion in the spread sheet  but has no effusion label (6) in the segmentation mask ['88033', '88034', '88138']\n"
     ]
    }
   ],
   "source": [
    "only_in_list1 = sorted(set(ids_effusion) - set(df_2D_effusion))\n",
    "only_in_list2 = sorted(set(df_2D_effusion) - set(ids_effusion))\n",
    "\n",
    "print(\"effusion labeled on the masks but labeled no effusion in the spread sheet:\", only_in_list1)\n",
    "print(\"effusion in the spread sheet  but has no effusion label (6) in the segmentation mask\", only_in_list2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
